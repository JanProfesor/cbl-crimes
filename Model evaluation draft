from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer
from sklearn.model_selection import cross_val_score, KFold
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

#performance metrics on the testset of the TabNet model
#!!!!should be adapted to the orginal model code before usage

y_pred = model.predict(X_test)
if y_pred.ndim > 1:
    y_pred = y_pred.ravel()

mae = mean_absolute_error(y_test, y_pred)
rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"R-squared (RÂ²): {r2:.2f}")

#5-fold cross validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = []

for train_idx, val_idx in kf.split(X):
    X_tr, X_val = X[train_idx], X[val_idx]
    y_tr, y_val = y[train_idx], y[val_idx]

    model_cv = TabNetRegressor()
    model_cv.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=0)
    y_val_pred = model_cv.predict(X_val).ravel()
    cv_scores.append(mean_absolute_error(y_val, y_val_pred))

print("\n Cross-Validation (5-Fold MAE):")
print(f"Average CV MAE: {np.mean(cv_scores):.2f}")
print(f"Std Dev CV MAE: {np.std(cv_scores):.2f}")


#Feature importance
feature_importances = model.feature_importances_
feature_names = X.columns if hasattr(X, 'columns') else [f"Feature {i}" for i in range(len(feature_importances))]

fi_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(fi_df['Feature'], fi_df['Importance'])
plt.gca().invert_yaxis()
plt.title("ðŸ§  TabNet Feature Importance")
plt.xlabel("Importance Score")
plt.tight_layout()
plt.show()
